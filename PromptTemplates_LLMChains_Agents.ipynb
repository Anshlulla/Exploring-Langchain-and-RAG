{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpLqJy5Ob3dV3nhBWy5bSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshlulla/Exploring-Langchain-and-RAG/blob/main/PromptTemplates_LLMChains_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Caching LLM Responses"
      ],
      "metadata": {
        "id": "sOQBG09r13DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###InMemoryCaching"
      ],
      "metadata": {
        "id": "ctTLU2OV4DkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai langchain-google-genai --q"
      ],
      "metadata": {
        "id": "Dg7eTOpT2Kl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a98b19-1d00-435f-fce9-8b62feedb34e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/41.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m666.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/408.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m368.6/408.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community --q"
      ],
      "metadata": {
        "id": "ugqIUUX43wLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5691f1-46ab-4af3-eab9-1f8788a87fcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJEIC1Hv1zui",
        "outputId": "805aa505-78e9-40b9-b51f-60d2a41daf9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "from langchain.globals import set_llm_cache\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.1, max_output_tokens=256, api_key=api_key)\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyKzOLRy2-rZ",
        "outputId": "3a8cbcaa-6828-4e17-a872-112f2cb08ff7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleGenerativeAI(model='gemini-pro', google_api_key=SecretStr('**********'), temperature=0.1, max_output_tokens=256, client=genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              "    cached_content=None\n",
              "))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from langchain.cache import InMemoryCache\n",
        "set_llm_cache(InMemoryCache())\n",
        "prompt = \"Tell me a political joke?\"\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "RfOqkf2Z3WqL",
        "outputId": "50f24216-4291-450d-9aca-c391709b11d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 565 ms, sys: 37.2 ms, total: 602 ms\n",
            "Wall time: 1.98 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the politician cross the road?\\n\\nTo get to the other side of the aisle.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZUcckEyp3sql",
        "outputId": "a58d1866-f30a-4f08-ddbd-580006eceb69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 516 µs, sys: 0 ns, total: 516 µs\n",
            "Wall time: 523 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the politician cross the road?\\n\\nTo get to the other side of the aisle.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SQLiteCaching"
      ],
      "metadata": {
        "id": "GPSGysQ34F2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from langchain.cache import SQLiteCache\n",
        "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qZsv48HJ39-w",
        "outputId": "f58b7f55-2fbf-424d-91c4-7a4bd8629fae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 47 ms, sys: 6.03 ms, total: 53 ms\n",
            "Wall time: 1.12 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What do you call a boomerang that won't come back?\\n\\nA stick.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "nzpue11a4TtV",
        "outputId": "6d9344a3-772b-4299-a913-7f536534d3cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 170 ms, sys: 57 ms, total: 227 ms\n",
            "Wall time: 494 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What do you call a boomerang that won't come back?\\n\\nA stick.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM Streaming"
      ],
      "metadata": {
        "id": "qHpVLk3F4jrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.1, streaming=True, api_key=api_key)"
      ],
      "metadata": {
        "id": "yRjIn2rN4fAv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in llm.stream(\"Write a movie script\"):\n",
        "  print(chunk, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aE841ah4vRQ",
        "outputId": "1764ebdc-e0d0-4afe-a664-ff3391bb5e94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**INT. APARTMENT - NIGHT**\n",
            "\n",
            "A young woman, ANNA, 25, sits on the couch, staring at the TV. She is clearly upset.\n",
            "\n",
            "ANNA\n",
            "(to herself)\n",
            "I can't believe he's gone.\n",
            "\n",
            "She gets up and walks over to the window. She looks out at the city below.\n",
            "\n",
            "ANNA (cont'd)\n",
            "I thought we had something special.\n",
            "\n",
            "She turns away from the window and walks back to the couch. She picks up a picture of her and her boyfriend, MARK.\n",
            "\n",
            "ANNA (cont'd)\n",
            "I miss you so much.\n",
            "\n",
            "She puts the picture down and lies back on the couch. She closes her eyes and tries to sleep.\n",
            "\n",
            "**INT. APARTMENT - DAY**\n",
            "\n",
            "Anna wakes up and gets out of bed. She walks over to the window and looks out. The sun is shining and the birds are singing.\n",
            "\n",
            "ANNA\n",
            "(to herself)\n",
            "It's a new day.\n",
            "\n",
            "She walks over to the bathroom and brushes her teeth. She then goes into the kitchen and makes a cup of coffee.\n",
            "\n",
            "ANNA (cont'd)\n",
            "I'm going to be okay.\n",
            "\n",
            "She takes a sip of her coffee and smiles.\n",
            "\n",
            "**INT. PARK - DAY**\n",
            "\n",
            "Anna is sitting on a bench in the park. She is reading a book.\n",
            "\n",
            "A young man, DAVID, 25, walks over to her.\n",
            "\n",
            "DAVID\n",
            "Excuse me, is this seat taken?\n",
            "\n",
            "ANNA\n",
            "No, it's not.\n",
            "\n",
            "DAVID\n",
            "Thanks.\n",
            "\n",
            "He sits down next to her.\n",
            "\n",
            "DAVID (cont'd)\n",
            "I'm David.\n",
            "\n",
            "ANNA\n",
            "I'm Anna.\n",
            "\n",
            "DAVID\n",
            "It's nice to meet you, Anna.\n",
            "\n",
            "ANNA\n",
            "It's nice to meet you too, David.\n",
            "\n",
            "They talk for a while. Anna finds herself drawn to David. He is kind, funny, and intelligent.\n",
            "\n",
            "**INT. APARTMENT - NIGHT**\n",
            "\n",
            "Anna is lying in bed, thinking about David. She smiles.\n",
            "\n",
            "ANNA\n",
            "(to herself)\n",
            "I think I'm falling in love with him.\n",
            "\n",
            "She closes her eyes and falls asleep.\n",
            "\n",
            "**INT. PARK - DAY**\n",
            "\n",
            "Anna and David are sitting on the bench in the park again. They are holding hands.\n",
            "\n",
            "DAVID\n",
            "I love you, Anna.\n",
            "\n",
            "ANNA\n",
            "I love you too, David.\n",
            "\n",
            "They kiss.\n",
            "\n",
            "**INT. APARTMENT - NIGHT**\n",
            "\n",
            "Anna and David are lying in bed together. They are both asleep.\n",
            "\n",
            "ANNA\n",
            "(in her sleep)\n",
            "I'm so happy.\n",
            "\n",
            "DAVID\n",
            "(in his sleep)\n",
            "Me too.\n",
            "\n",
            "They both smile and drift off to sleep.\n",
            "\n",
            "**FADE OUT.**"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PromptTemplates"
      ],
      "metadata": {
        "id": "DV6ghPHE5cr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Useful in scenarios of Question Answering or Completing Sentences"
      ],
      "metadata": {
        "id": "vOsQmRM56_52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"You are an experienced SongWriter. Write a short song about {topic} in {language}\"\n",
        "prompt = PromptTemplate.from_template(template=template)\n",
        "prompt = prompt.format(topic=\"The Beauty of Mumbai\", language=\"english\")\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MDLcVfBd4191",
        "outputId": "0c2f1245-b982-4561-f0e6-961f2f44aff7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are an experienced SongWriter. Write a short song about The Beauty of Mumbai in english'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(prompt)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIYvHX0d6Y5d",
        "outputId": "d0b62153-65e0-4bbc-ae57-cbcd7c60ff4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Verse 1)\n",
            "In the heart of India's west,\n",
            "Where dreams and chaos intertwine,\n",
            "Lies a city of vibrant zest,\n",
            "Mumbai, a beauty so divine.\n",
            "\n",
            "(Chorus)\n",
            "Oh, Mumbai, Mumbai,\n",
            "A symphony of colors and sound,\n",
            "Where skyscrapers touch the sky,\n",
            "And ancient streets abound.\n",
            "\n",
            "(Verse 2)\n",
            "From the Gateway of India's grace,\n",
            "To the bustling markets' lively pace,\n",
            "Each corner tells a different tale,\n",
            "Of a city that never fails.\n",
            "\n",
            "(Chorus)\n",
            "Oh, Mumbai, Mumbai,\n",
            "A symphony of colors and sound,\n",
            "Where skyscrapers touch the sky,\n",
            "And ancient streets abound.\n",
            "\n",
            "(Bridge)\n",
            "The sea breeze whispers secrets sweet,\n",
            "As the sun sets, casting a golden hue,\n",
            "The city transforms, a vibrant beat,\n",
            "Where dreams and aspirations come true.\n",
            "\n",
            "(Verse 3)\n",
            "From Bollywood's glitz to art's embrace,\n",
            "Mumbai's culture knows no bounds,\n",
            "A melting pot of every race,\n",
            "Where creativity forever resounds.\n",
            "\n",
            "(Chorus)\n",
            "Oh, Mumbai, Mumbai,\n",
            "A symphony of colors and sound,\n",
            "Where skyscrapers touch the sky,\n",
            "And ancient streets abound.\n",
            "\n",
            "(Outro)\n",
            "In the heart of India's west,\n",
            "Mumbai's beauty stands the test,\n",
            "A city of dreams, a vibrant soul,\n",
            "Where the spirit of India takes its toll.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ChatPromptTemplates"
      ],
      "metadata": {
        "id": "sQTMHgzi7Jyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Useful in scenarios when user wishes to interact with the LLM in a conversation"
      ],
      "metadata": {
        "id": "VummhhNY6fbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> HumanMessagePromptTemplate allows you to create dynamic prompts from the User Message"
      ],
      "metadata": {
        "id": "-p3E5rv97fMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> They help improve usability, scalability and accuracy."
      ],
      "metadata": {
        "id": "_cESnM6q8m8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(\"You respond only in the JSON Format.\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"Top {n} countries in {area} by population.\")\n",
        "])\n",
        "\n",
        "chat_prompt_template = chat_prompt_template.format(n=10, area=\"Asia\")\n",
        "chat_prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_wgWjt3W7ST0",
        "outputId": "a2bfa9ab-f083-49e7-d383-b811ac825e63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'System: You respond only in the JSON Format.\\nHuman: Top 10 countries in Asia by population.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(chat_prompt_template))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndNzjXYD7eLO",
        "outputId": "9c73d519-1eb8-4cef-b3be-1c8b7b3332b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"countries\": [\n",
            "    {\n",
            "      \"name\": \"China\",\n",
            "      \"population\": 1444015000\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"India\",\n",
            "      \"population\": 1380004385\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Indonesia\",\n",
            "      \"population\": 273523615\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Pakistan\",\n",
            "      \"population\": 220892340\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Bangladesh\",\n",
            "      \"population\": 164689383\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Japan\",\n",
            "      \"population\": 126476461\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Philippines\",\n",
            "      \"population\": 109581078\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Vietnam\",\n",
            "      \"population\": 97338583\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Turkey\",\n",
            "      \"population\": 84339067\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Iran\",\n",
            "      \"population\": 83992949\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Chains"
      ],
      "metadata": {
        "id": "0ohjU3NU8SlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "llm = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.1, api_key=api_key)\n",
        "template = \"You are an experienced ScriptWriter. Write a movie script about {topic}.\"\n",
        "prompt = PromptTemplate.from_template(template=template)\n",
        "\n",
        "# Creating the chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "\n",
        "# Returns a dictionary\n",
        "output = chain.invoke({\"topic\": \"The Beauty of Mumbai\"})\n",
        "print(output[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEriVh-a9C-t",
        "outputId": "805d04c3-f3fa-4ce8-c0d0-934dd8eb8c68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an experienced ScriptWriter. Write a movie script about The Beauty of Mumbai.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-7bf7c43cd696>:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "**INT. MUMBAI - DAY**\n",
            "\n",
            "A montage of vibrant images of Mumbai:\n",
            "\n",
            "* The Gateway of India, with boats bobbing in the harbor\n",
            "* The bustling streets of Colaba Causeway\n",
            "* The iconic Victoria Terminus railway station\n",
            "* The crowded beaches of Juhu\n",
            "* The towering skyscrapers of Bandra Kurla Complex\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai, a city of dreams, a city of contrasts. A city where the ancient and the modern collide, where the sacred and the profane intertwine.\n",
            "\n",
            "**EXT. MARINE DRIVE - DAY**\n",
            "\n",
            "A young woman, ANJALI, walks along the promenade, her eyes taking in the beauty of the city.\n",
            "\n",
            "**ANJALI**\n",
            "\n",
            "(to herself)\n",
            "\n",
            "I've always loved Mumbai. It's a city that's always changing, always evolving.\n",
            "\n",
            "**EXT. CHOWPATTY BEACH - DAY**\n",
            "\n",
            "A group of children play in the sand, while their parents watch from the sidelines.\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai is a city of people. People from all walks of life, from all corners of the world.\n",
            "\n",
            "**EXT. DHARAVI SLUM - DAY**\n",
            "\n",
            "A maze of narrow streets and makeshift homes.\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai is a city of contrasts. A city of wealth and poverty, of beauty and squalor.\n",
            "\n",
            "**EXT. BANDRA-WORLI SEA LINK - DAY**\n",
            "\n",
            "A modern marvel, the Bandra-Worli Sea Link connects the city's two main business districts.\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai is a city of dreams. A city where anything is possible, if you're willing to work hard enough.\n",
            "\n",
            "**EXT. MUMBAI LOCAL TRAIN - DAY**\n",
            "\n",
            "A crowded train, packed with commuters.\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai is a city of resilience. A city that has weathered countless storms, both natural and man-made.\n",
            "\n",
            "**EXT. MUMBAI AT NIGHT - NIGHT**\n",
            "\n",
            "The city lights up, a glittering metropolis.\n",
            "\n",
            "**NARRATOR (V.O.)**\n",
            "\n",
            "Mumbai is a city of beauty. A city that will forever hold a special place in my heart.\n",
            "\n",
            "**FADE OUT.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SequentialChains"
      ],
      "metadata": {
        "id": "W1wrtPCE_FrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai --q\n",
        "!pip install --upgrade langchain-google-genai --q"
      ],
      "metadata": {
        "id": "L65T80kbGS9Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai langchain --q"
      ],
      "metadata": {
        "id": "9IOgONMZKCB2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai --q"
      ],
      "metadata": {
        "id": "yl-96Rw-KJRZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Initialize the LLM (Gemini) for script generation\n",
        "llm1 = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.8, api_key=api_key)\n",
        "script_prompt = PromptTemplate(\n",
        "    template=\"You are an experienced ScriptWriter. Write a detailed movie script about the topic: {topic}.\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "script_chain = LLMChain(llm=llm1, prompt=script_prompt, output_key=\"script\")\n",
        "\n",
        "# Initialize the LLM (Gemini) for character descriptions\n",
        "llm2 = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7, api_key=api_key)\n",
        "character_prompt = PromptTemplate(\n",
        "    template=\"Based on the following movie script, provide character descriptions:\\n\\nScript:\\n{script}\",\n",
        "    input_variables=[\"script\"]\n",
        ")\n",
        "character_chain = LLMChain(llm=llm2, prompt=character_prompt, output_key=\"character_descriptions\")\n",
        "\n",
        "# Set up a SimpleSequentialChain to link both chains\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[script_chain, character_chain],\n",
        "    input_key=\"topic\",\n",
        "    output_key=\"character_descriptions\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Running the chain with the topic as input\n",
        "output = overall_chain({\"topic\": \"A romantic scene in NYC\"})\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U503UzQT-G-3",
        "outputId": "8ea7456c-7283-4171-803c-ae32a5bb2c7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-c4276f3074ff>:30: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  output = overall_chain({\"topic\": \"A romantic scene in NYC\"})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mNo script was provided, so I cannot provide character descriptions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'topic': 'A romantic scene in NYC', 'character_descriptions': 'No script was provided, so I cannot provide character descriptions.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Initialize the LLM (Gemini) for script generation\n",
        "llm1 = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.8, api_key=api_key)\n",
        "script_prompt = PromptTemplate(\n",
        "    template=\"You are an experienced ScriptWriter. Write a detailed movie script about the topic: {topic}.\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "script_chain = LLMChain(llm=llm1, prompt=script_prompt, output_key=\"script\")\n",
        "\n",
        "# Run the first chain to get the movie script\n",
        "script_output = script_chain.run({\"topic\": \"A romantic scene in NYC\"})\n",
        "print(script_output)\n",
        "\n",
        "# Initialize the LLM (Gemini) for character descriptions\n",
        "llm2 = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7, api_key=api_key)\n",
        "character_prompt = PromptTemplate(\n",
        "    template=\"Based on the following movie script, provide character descriptions:\\n\\nScript:\\n{script}\",\n",
        "    input_variables=[\"script\"]\n",
        ")\n",
        "character_chain = LLMChain(llm=llm2, prompt=character_prompt, output_key=\"character_descriptions\")\n",
        "\n",
        "# Run the second chain using the script output as input\n",
        "character_descriptions_output = character_chain.run({\"script\": script_output})\n",
        "\n",
        "# Print the character descriptions\n",
        "print(character_descriptions_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiUEBQu6A-qB",
        "outputId": "ee171db2-72e4-4ee9-8d71-dc23c019d68c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No script was provided, so I cannot provide character descriptions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-acf275d1b1f8>:14: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  script_output = script_chain.run({\"topic\": \"A romantic scene in NYC\"})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LangChain Agents"
      ],
      "metadata": {
        "id": "U21_PCH9Fvo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Python REPL"
      ],
      "metadata": {
        "id": "SPCJ_sUIgwXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental --q"
      ],
      "metadata": {
        "id": "mYSf02F9Igme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cecd657-94be-49e7-984c-a49acc8518ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m194.6/209.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "python_repl = PythonREPL()\n",
        "python_repl.run(\"print([n for n in range(1,100) if n%13==0])\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fWw0kMNkRAzs",
        "outputId": "826526b9-f035-4598-9d0b-91311c3544ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[13, 26, 39, 52, 65, 78, 91]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=llm,\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "agent_executor.invoke(\"5.1 ** 7.3 \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A848z9KRWqO",
        "outputId": "d2a1766e-8918-4297-b873-0f087d19ebf3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
            "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 146306.05007233328\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '5.1 ** 7.3 ', 'output': '146306.05007233328'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DuckDuckGo and Wikipedia"
      ],
      "metadata": {
        "id": "1TMKPskQgtJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q duckduckgo-search wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBWUVLL9gtFu",
        "outputId": "8bec2077-5769-4bad-c720-af356112c3a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "output = search.invoke(\"WWhat is John Mayer's best song?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBLqhkoNhE5x",
        "outputId": "23b86faf-1a50-4beb-b3e1-d95eb2fe5cf0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The John Mayer song oozes emotion, as Mayer's lyrics are revealed in a confessionalist tone while smooth, clean electric guitar fills swell into empty spaces between vocal lines. \"Gravity, stay the hell away from me.\" One of fans' favorite things about Mayer is his brutally honest lyrical mastery. List of John Mayer songs, ranked from best to worst by the Ranker community. Bringing a touch of the blues to pop music, John Mayer is a guitar virtuoso and a masterful songwriter who dropped out of the Berklee College of Music to begin his career. All of John Mayer's singles are included here, but real fans know there are other awesome songs to vote on other than \"Your Body Is a Wonderland ... The song, which peaked at number 71 on the Billboard Hot 100, was published in 2006 as part of John's album \"Continuum.\"It had a big influence on the charts. If you're a fan, you are well aware. Guitar Habits thinks that it is superb in every way.. Electric blues is Mayer's forte, and \"Slow Dancing in a Burning Room\" is one of his best. \"Daughters\": the one that got the \"Song of the Year\" Grammy \"Edge of Desire\": the pound-for-pound best etc. etc. etc. But through all of the great songs, there has to be a 1v1 battle between \"Gravity\" and \"Slow Dancing In a Burning Room\". Think about it. Those songs made an entire generation pick up a Strat. They are simple chord progressions. The Meaning Behind The Song: Slow Dancing in a Burning Room by John Mayer. John Mayer's \"Slow Dancing in a Burning Room\" is a soulful and emotionally-charged song that has captivated audiences around the world. Released in 2006 as part of Mayer's Grammy-winning album \"Continuum,\" the song delves into themes of heartbreak, love, and ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search.name, search.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwce__mHhR2E",
        "outputId": "2d9f2a13-2396-42fd-943a-3d9b3776b265"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('duckduckgo_search',\n",
              " 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For additional information such as links, use duckduckgosearchresults\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "\n",
        "search = DuckDuckGoSearchResults()\n",
        "output = search.run(\"What is John Mayer's best song?\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J28OjBZ-hmA8",
        "outputId": "32878184-4ff6-47d5-fdf8-c2f8d7b500d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "snippet: The John Mayer song oozes emotion, as Mayer's lyrics are revealed in a confessionalist tone while smooth, clean electric guitar fills swell into empty spaces between vocal lines. \"Gravity, stay the hell away from me.\" One of fans' favorite things about Mayer is his brutally honest lyrical mastery., title: 12 Best John Mayer Songs From His Stunning Career So Far - Zing Instruments, link: https://zinginstruments.com/best-john-mayer-songs/, snippet: The breathy hit netted Mayer his first career GRAMMY Award, for Best Male Pop Vocal Performance, at the 45th Annual GRAMMY Awards in 2003. ... 1 10 John Mayer Songs That Show His Versatility, From 'Room For Squares' To Dead & Co; 2 14 Must-Hear Albums In November: The Cure, Dolly Parton, Jin Of BTS, Ab-Soul, & More;, title: 10 John Mayer Songs That Show His Versatility, From 'Room For Squares ..., link: https://www.grammy.com/news/john-mayer-songs-discography-dead-and-company-vegas-residency, snippet: List of John Mayer songs, ranked from best to worst by the Ranker community. Bringing a touch of the blues to pop music, John Mayer is a guitar virtuoso and a masterful songwriter who dropped out of the Berklee College of Music to begin his career. All of John Mayer's singles are included here, but real fans know there are other awesome songs to vote on other than \"Your Body Is a Wonderland ..., title: The Best John Mayer Songs of All Time - Ranker, link: https://www.ranker.com/list/best-john-mayer-songs/voteable, snippet: The song, which peaked at number 71 on the Billboard Hot 100, was published in 2006 as part of John's album \"Continuum.\"It had a big influence on the charts. If you're a fan, you are well aware. Guitar Habits thinks that it is superb in every way.. Electric blues is Mayer's forte, and \"Slow Dancing in a Burning Room\" is one of his best., title: The 7 Greatest John Mayer Songs: Fans Picks - Study Finds, link: https://studyfinds.org/best-john-mayer-songs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "\n",
        "wrapper = DuckDuckGoSearchAPIWrapper(region=\"ind\", max_results=3, safesearch=\"moderate\")\n",
        "search = DuckDuckGoSearchResults(api_key=wrapper, source=\"news\")\n",
        "output = search.run(\"India\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG1ObBx_h6fe",
        "outputId": "76a82dcc-5065-4cc6-dff5-5946d40a09c6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "snippet: India, officially the Republic of India, [j] [21] is a country in South Asia.It is the seventh-largest country in the world by area and the most populous country.Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; [k] China, Nepal, and Bhutan to the north; and Bangladesh and ..., title: India - Wikipedia, link: https://en.wikipedia.org/wiki/India, snippet: Learn about India, the most populous country in the world, with a rich and diverse cultural heritage. Explore its history, geography, economy, politics, religions, languages, and more from Britannica., title: India | History, Map, Population, Economy, & Facts | Britannica, link: https://www.britannica.com/place/India, snippet: Learn about India, a country in South Asia with a diverse culture, history, and geography. Find out about its capital, flag, languages, religions, and more., title: India - Simple English Wikipedia, the free encyclopedia, link: https://simple.wikipedia.org/wiki/India, snippet: India News | Latest India News | Read latest and breaking news from India. Today's top India news headlines, news on Indian politics, elections, government, business, technology, and Bollywood., title: India News | Today's latest updates and breaking news from India, Live ..., link: https://www.ndtv.com/india\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern = r'snippet: (.*?), title: (,*?), link: (.*?)\\],'\n",
        "matches = re.findall(pattern, output, re.DOTALL)\n",
        "\n",
        "for snippet, title, link in matches:\n",
        "    print(f\"Snippet: {snippet}\")\n",
        "    print(f\"Title: {title}\")\n",
        "    print(f\"Link: {link}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "A5voawNWixyJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "output = wiki.invoke({\"query\": \"llama index\"})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FZzQ-q6jUL0",
        "outputId": "3092609d-7382-435c-e44a-5b4b6e9f85a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Vector database\n",
            "Summary: A vector database, vector store or vector search engine is a database that can store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more Approximate Nearest Neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
            "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension correspond\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ReAct Agents"
      ],
      "metadata": {
        "id": "pYzQSyZ-lxQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3waULEKncaZ",
        "outputId": "69f99b61-cf1b-4f53-8aa9-008ee505b435"
      },
      "execution_count": 51,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub -q"
      ],
      "metadata": {
        "id": "EAjlwEYJj_ke"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6qApRs6l6uf",
        "outputId": "68ab50d9-2620-49d3-d460-db38f568a808"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-pro', google_api_key=SecretStr('**********'), temperature=0.8, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7efa9c27af20>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain import hub\n",
        "from langchain.agents import initialize_agent, create_react_agent, Tool, AgentExecutor\n",
        "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a screenwriter who creates original movie scripts based on given themes\n",
        "    and context from similar scripts. Use the provided context as inspiration to write a new script\n",
        "    that fulfills the user's description. Avoid using HTML tags like <center>, avoid\n",
        "    using **, and return a plain, well-structured dialogue (or script).\n",
        "\n",
        "    If the context is minimal, proceed by using general suspense elements and improvising details\n",
        "    to create an engaging scene that fits the description.\n",
        "\n",
        "    Here are similar scripts for inspiration:\n",
        "    {context}\n",
        "\n",
        "    Now, create a new script based on this prompt:\n",
        "    {question}\n",
        "\n",
        "    {agent_scratchpad}\n",
        "    \"\"\"),\n",
        "])\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]), tools=tools, agent_scratchpad=\"\")\n",
        "print(type(prompt))\n",
        "print(prompt.input_variables)\n",
        "print(prompt.partial_variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKTK3rC8mBjx",
        "outputId": "3a4add4f-0bd2-42be-850f-86ab2a77cfd0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
            "['context', 'question']\n",
            "{'tool_names': 'python_repl, Wikipedia, DuckDuckGo', 'tools': [Tool(name='python_repl', description='Useful for executing python code', func=<bound method BaseTool.run of PythonREPLTool(python_repl=PythonREPL(globals={'__name__': 'langchain_experimental.tools.python.tool', '__doc__': 'A tool for running python code in a REPL.', '__package__': 'langchain_experimental.tools.python', '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x7efa9c3ad000>, '__spec__': ModuleSpec(name='langchain_experimental.tools.python.tool', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7efa9c3ad000>, origin='/usr/local/lib/python3.10/dist-packages/langchain_experimental/tools/python/tool.py'), '__file__': '/usr/local/lib/python3.10/dist-packages/langchain_experimental/tools/python/tool.py', '__cached__': '/usr/local/lib/python3.10/dist-packages/langchain_experimental/tools/python/__pycache__/tool.cpython-310.pyc', '__builtins__': {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7efade441d20>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
            "All Rights Reserved.\n",
            "\n",
            "Copyright (c) 2000 BeOpen.com.\n",
            "All Rights Reserved.\n",
            "\n",
            "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
            "All Rights Reserved.\n",
            "\n",
            "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
            "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
            "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., '__IPYTHON__': True, 'display': <function display at 0x7efae64c4ca0>, 'execfile': <function execfile at 0x7efacd515900>, 'runfile': <function runfile at 0x7efacd427910>, 'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7efade441db0>>}, 'ast': <module 'ast' from '/usr/lib/python3.10/ast.py'>, 're': <module 're' from '/usr/lib/python3.10/re.py'>, 'sys': <module 'sys' (built-in)>, 'redirect_stdout': <class 'contextlib.redirect_stdout'>, 'StringIO': <class '_io.StringIO'>, 'Any': typing.Any, 'Dict': typing.Dict, 'Optional': typing.Optional, 'Type': typing.Type, 'AsyncCallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.AsyncCallbackManagerForToolRun'>, 'CallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.CallbackManagerForToolRun'>, 'run_in_executor': <function run_in_executor at 0x7efaa543e320>, 'BaseTool': <class 'langchain_core.tools.base.BaseTool'>, 'BaseModel': <class 'pydantic.main.BaseModel'>, 'Field': <function Field at 0x7efaa5f805e0>, 'model_validator': <function model_validator at 0x7efaa659ec20>, 'PythonREPL': <class 'langchain_experimental.utilities.python.PythonREPL'>, '_get_default_python_repl': <function _get_default_python_repl at 0x7efa8ef4a4d0>, 'sanitize_input': <function sanitize_input at 0x7efa8ef4a560>, 'PythonREPLTool': <class 'langchain_experimental.tools.python.tool.PythonREPLTool'>, 'PythonInputs': <class 'langchain_experimental.tools.python.tool.PythonInputs'>, 'PythonAstREPLTool': <class 'langchain_experimental.tools.python.tool.PythonAstREPLTool'>}, locals=None))>), Tool(name='Wikipedia', description='Useful when you want to search about a query over Wikipedia', func=<bound method BaseTool.run of WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=500))>), Tool(name='DuckDuckGo', description='Useful when you want to search about a query over the internet', func=<bound method BaseTool.run of DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='api', source='text'))>)], 'agent_scratchpad': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. PythonREPL Tool (for executing Python Code)\n",
        "python_repl = PythonREPLTool()\n",
        "python_repl_tool = Tool(\n",
        "    name=\"python_repl\",\n",
        "    func=python_repl.run,\n",
        "    description=\"Useful for executing python code\"\n",
        ")\n",
        "\n",
        "# 2. Wikipedia Tool (for searching Wikipedia)\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=500)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "wiki_tool = Tool(\n",
        "    name=\"Wikipedia\",\n",
        "    func=wiki.run,\n",
        "    description=\"Useful when you want to search about a query over Wikipedia\"\n",
        ")\n",
        "\n",
        "# 3. DuckDuckGoSearch Tool (for general web searches)\n",
        "search = DuckDuckGoSearchRun()\n",
        "duckduckgo_tool = Tool(\n",
        "    name=\"DuckDuckGo\",\n",
        "    func=search.run,\n",
        "    description=\"Useful when you want to search about a query over the internet\"\n",
        ")\n",
        "\n",
        "tools = [python_repl_tool, wiki_tool, duckduckgo_tool]"
      ],
      "metadata": {
        "id": "RrR7XhSmnIlE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10\n",
        ")"
      ],
      "metadata": {
        "id": "Y_m3UCvBpe7s"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "[Context of similar scripts here, such as snippets or themes.\n",
        "For instance, you might include dialogue from a detective thriller or a romance drama for inspiration.]\n",
        "\"\"\"\n",
        "\n",
        "query = \"Create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\"\n",
        "\n",
        "try:\n",
        "    result = agent_executor({\n",
        "        \"context\": context,\n",
        "        \"question\": query\n",
        "    })\n",
        "    print(\"Generated Script:\\n\", result['output'])\n",
        "except Exception as e:\n",
        "    print(f\"Error during script generation: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK6X5HJbpxxN",
        "outputId": "d120e212-979d-47ae-80df-9087044e3045"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI do not have enough information to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information about the setting of the story to create a scene based on your request.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information in the provided context to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI am sorry, but the context provided does not contain any information about a scene for a suspense thriller featuring a detective confronting a main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI do not have enough information to create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI am sorry, but I cannot create a scene for a suspense thriller where a detective confronts the main suspect in a dimly lit alley based on the provided context.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI'm sorry, but I cannot create the requested scene based on the provided context. The context does not mention any details about a dimly lit alley or a detective confronting a suspect.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Generated Script:\n",
            " Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    }
  ]
}